{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예측 함수\n",
    "\n",
    "$$\n",
    "Y = Wx + b\n",
    "$$\n",
    "\n",
    "x는 특성, y는 예측 값이다. \n",
    "W는 기울기, b는 y절편을 뜻하지만 W는 가중치(weight), b는 offset으로 부를 수도 있다.\n",
    "선형 회귀에서는 여러 샘플의 특성 값과 예측 값을 활용해 가장 적절한 w와 b를 구하는 것이 목적이다.\n",
    "### 평균 제곱 오차 (Mean Square Error)\n",
    "선형 회귀에서는 Coast 함수(또는 비용 함수)로 평균 제곱 오차를 사용한다. \n",
    "여기서 Coast 함수란 샘플 데이터와 타깃과의 유사도를 의미하며 Coast 함수가 최소가 되도록 \n",
    "파라미터를 학습시킨다. \n",
    "$$\n",
    "   \\frac{1}{n}\\sum(pred_i - y_i)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([1.,2,3,4,5,6])\n",
    "y = np.array([9.,16,23,30,37,44])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "w= 0.0\n",
    "b= 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_data = len(X)\n",
    "n_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5000 # 최대학습회수 // 한 회수 = n_data 한 번 훑음\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0/5000, w : 1.1317, b : 0.2650, loss : 845.1667\n",
      "Epoch : 100/5000, w : 7.0672, b : 1.7122, loss : 0.0160\n",
      "Epoch : 200/5000, w : 7.0560, b : 1.7603, loss : 0.0111\n",
      "Epoch : 300/5000, w : 7.0466, b : 1.8003, loss : 0.0077\n",
      "Epoch : 400/5000, w : 7.0389, b : 1.8336, loss : 0.0053\n",
      "Epoch : 500/5000, w : 7.0324, b : 1.8614, loss : 0.0037\n",
      "Epoch : 600/5000, w : 7.0270, b : 1.8845, loss : 0.0026\n",
      "Epoch : 700/5000, w : 7.0225, b : 1.9038, loss : 0.0018\n",
      "Epoch : 800/5000, w : 7.0187, b : 1.9199, loss : 0.0012\n",
      "Epoch : 900/5000, w : 7.0156, b : 1.9332, loss : 0.0009\n",
      "Epoch : 1000/5000, w : 7.0130, b : 1.9444, loss : 0.0006\n",
      "Epoch : 1100/5000, w : 7.0108, b : 1.9537, loss : 0.0004\n",
      "Epoch : 1200/5000, w : 7.0090, b : 1.9614, loss : 0.0003\n",
      "Epoch : 1300/5000, w : 7.0075, b : 1.9678, loss : 0.0002\n",
      "Epoch : 1400/5000, w : 7.0063, b : 1.9732, loss : 0.0001\n",
      "Epoch : 1500/5000, w : 7.0052, b : 1.9777, loss : 0.0001\n",
      "Epoch : 1600/5000, w : 7.0043, b : 1.9814, loss : 0.0001\n",
      "Epoch : 1700/5000, w : 7.0036, b : 1.9845, loss : 0.0000\n",
      "Epoch : 1800/5000, w : 7.0030, b : 1.9871, loss : 0.0000\n",
      "Epoch : 1900/5000, w : 7.0025, b : 1.9893, loss : 0.0000\n",
      "Epoch : 2000/5000, w : 7.0021, b : 1.9910, loss : 0.0000\n",
      "Epoch : 2100/5000, w : 7.0017, b : 1.9925, loss : 0.0000\n",
      "Epoch : 2200/5000, w : 7.0015, b : 1.9938, loss : 0.0000\n",
      "Epoch : 2300/5000, w : 7.0012, b : 1.9948, loss : 0.0000\n",
      "Epoch : 2400/5000, w : 7.0010, b : 1.9957, loss : 0.0000\n",
      "Epoch : 2500/5000, w : 7.0008, b : 1.9964, loss : 0.0000\n",
      "Epoch : 2600/5000, w : 7.0007, b : 1.9970, loss : 0.0000\n",
      "Epoch : 2700/5000, w : 7.0006, b : 1.9975, loss : 0.0000\n",
      "Epoch : 2800/5000, w : 7.0005, b : 1.9979, loss : 0.0000\n",
      "Epoch : 2900/5000, w : 7.0004, b : 1.9983, loss : 0.0000\n",
      "Epoch : 3000/5000, w : 7.0003, b : 1.9986, loss : 0.0000\n",
      "Epoch : 3100/5000, w : 7.0003, b : 1.9988, loss : 0.0000\n",
      "Epoch : 3200/5000, w : 7.0002, b : 1.9990, loss : 0.0000\n",
      "Epoch : 3300/5000, w : 7.0002, b : 1.9992, loss : 0.0000\n",
      "Epoch : 3400/5000, w : 7.0002, b : 1.9993, loss : 0.0000\n",
      "Epoch : 3500/5000, w : 7.0001, b : 1.9994, loss : 0.0000\n",
      "Epoch : 3600/5000, w : 7.0001, b : 1.9995, loss : 0.0000\n",
      "Epoch : 3700/5000, w : 7.0001, b : 1.9996, loss : 0.0000\n",
      "Epoch : 3800/5000, w : 7.0001, b : 1.9997, loss : 0.0000\n",
      "Epoch : 3900/5000, w : 7.0001, b : 1.9997, loss : 0.0000\n",
      "Epoch : 4000/5000, w : 7.0001, b : 1.9998, loss : 0.0000\n",
      "Epoch : 4100/5000, w : 7.0000, b : 1.9998, loss : 0.0000\n",
      "Epoch : 4200/5000, w : 7.0000, b : 1.9998, loss : 0.0000\n",
      "Epoch : 4300/5000, w : 7.0000, b : 1.9999, loss : 0.0000\n",
      "Epoch : 4400/5000, w : 7.0000, b : 1.9999, loss : 0.0000\n",
      "Epoch : 4500/5000, w : 7.0000, b : 1.9999, loss : 0.0000\n",
      "Epoch : 4600/5000, w : 7.0000, b : 1.9999, loss : 0.0000\n",
      "Epoch : 4700/5000, w : 7.0000, b : 1.9999, loss : 0.0000\n",
      "Epoch : 4800/5000, w : 7.0000, b : 1.9999, loss : 0.0000\n",
      "Epoch : 4900/5000, w : 7.0000, b : 2.0000, loss : 0.0000\n",
      "--------------------------------------------------------------------------------\n",
      "최종\n",
      "W : 7.0000 \n",
      "B : 2.0000 \n",
      "Result : [ 8.99997131 15.99998006 22.9999888  29.99999754 37.00000628 44.00001503]\n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    # 예측을 해야 Loss가 나오고 그래야 학습이 진행됨\n",
    "    y_predict = X*w+b\n",
    "    \n",
    "    # Loss 계산\n",
    "    loss = np.sum((y_predict-y)**2)/ n_data\n",
    "    \n",
    "    # 학습 : W, b 보정\n",
    "    w -= learning_rate* ((y_predict-y)*X).mean()\n",
    "    b -= learning_rate* (y_predict-y).mean()\n",
    "    \n",
    "    # 충분히 공부했으면 빠지기 근데 이번에는 전체적으로 다 확인해봄\n",
    "    if i % 100 == 0 :\n",
    "        print('Epoch : {}/{}, w : {:.4f}, b : {:.4f}, loss : {:.4f}' .format(i,epochs,w,b,loss))\n",
    "print('--------'*10)\n",
    "print('최종')\n",
    "print('W : {:.4f} \\nB : {:.4f} \\nResult : {}' .format(w,b,X*w+b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
