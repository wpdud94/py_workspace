{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "[2020-09-04 13:42:52,643] ERROR in app: Exception on /predict [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\kjy\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\kjy\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 1953, in full_dispatch_request\n",
      "    return self.finalize_request(rv)\n",
      "  File \"C:\\kjy\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 1968, in finalize_request\n",
      "    response = self.make_response(rv)\n",
      "  File \"C:\\kjy\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 2112, in make_response\n",
      "    rv = jsonify(rv)\n",
      "  File \"C:\\kjy\\anaconda3\\lib\\site-packages\\flask\\json\\__init__.py\", line 370, in jsonify\n",
      "    dumps(data, indent=indent, separators=separators) + \"\\n\",\n",
      "  File \"C:\\kjy\\anaconda3\\lib\\site-packages\\flask\\json\\__init__.py\", line 211, in dumps\n",
      "    rv = _json.dumps(obj, **kwargs)\n",
      "  File \"C:\\kjy\\anaconda3\\lib\\site-packages\\simplejson\\__init__.py\", line 412, in dumps\n",
      "    **kw).encode(obj)\n",
      "  File \"C:\\kjy\\anaconda3\\lib\\site-packages\\simplejson\\encoder.py\", line 296, in encode\n",
      "    chunks = self.iterencode(o, _one_shot=True)\n",
      "  File \"C:\\kjy\\anaconda3\\lib\\site-packages\\simplejson\\encoder.py\", line 378, in iterencode\n",
      "    return _iterencode(o, 0)\n",
      "  File \"C:\\kjy\\anaconda3\\lib\\site-packages\\flask\\json\\__init__.py\", line 100, in default\n",
      "    return _json.JSONEncoder.default(self, o)\n",
      "  File \"C:\\kjy\\anaconda3\\lib\\site-packages\\simplejson\\encoder.py\", line 273, in default\n",
      "    o.__class__.__name__)\n",
      "TypeError: Object of type Tensor is not JSON serializable\n",
      "127.0.0.1 - - [04/Sep/2020 13:42:52] \"\u001b[35m\u001b[1mPOST /predict HTTP/1.1\u001b[0m\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import pdb # for문 안에서 어떻게 진행되나 확인하는 것 -- about Debug\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "from flask_restful import Resource, Api\n",
    "from scipy import misc\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "import Domain\n",
    "\n",
    "app = Flask(__name__)\n",
    "cors = CORS(app, resources={r'*': {'origins': '*'}})\n",
    "\n",
    "@app.route(\"/predict\", methods = ['POST'])\n",
    "def predict():\n",
    "    if request.method == 'POST':\n",
    "        file = request.files['image']\n",
    "        file.save(file.filename)\n",
    "        \n",
    "        # Hyper params\n",
    "        num_epochs = 5\n",
    "        num_classes = 10\n",
    "        batch_size = 100\n",
    "        learning_rate = 0.001\n",
    "        \n",
    "        trans = transforms.Compose([\n",
    "            transforms.Resize((28,28)),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        testset = torchvision.datasets.ImageFolder(root=\"C:\\kjy\\py_workspace\\Flask_Practice\", transform=trans)\n",
    "        testloader = torch.utils.data.DataLoader(dataset=testset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        # 모델 초기화\n",
    "        model = ConvNet()\n",
    "        # 기존 weights 입력\n",
    "        model.load_state_dict(torch.load('model_state_dict.pt',map_location=device))\n",
    "        # 모델 실행\n",
    "        model.eval()\n",
    "        \n",
    "        # 예측하기\n",
    "        for image, label in testloader:\n",
    "            image=image.to(device)\n",
    "            outputs = model(image[:,:1])\n",
    "            _,predicted=torch.max(outputs.data, 1)\n",
    "            print(predicted[0])\n",
    "        \n",
    "        return str(predicted.numpy()[0])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":              \n",
    "    app.run(host=\"127.0.0.1\", port=\"5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 껍데기\n",
    "class ConvNet(nn.Module) :\n",
    "  def __init__(self, num_classes=10):\n",
    "    super(ConvNet, self).__init__()\n",
    "    # CL, ML, FL 등이 선형적으로 연결됨 --> sequential\n",
    "    # sequential 써도 되고... 따로 만들어도 되고\n",
    "    # 튜토리얼 : pytorch nn.conv2d 검색\n",
    "    self.layer1 = nn.Sequential(\n",
    "      nn.Conv2d(1,16,kernel_size=5,stride=1,padding=2),\n",
    "      nn.ReLU()\n",
    "    )# (28*28*16)\n",
    "    self.layer2 = nn.MaxPool2d(kernel_size=2,stride=2) # (14*14*16)\n",
    "    self.layer3 = nn.Sequential(\n",
    "      nn.Conv2d(16,32,kernel_size=5,stride=1,padding=2), # 위 conv에서 ch 늘린 만큼 채널 넣어준다\n",
    "      nn.ReLU()\n",
    "    )# (14*14*32)\n",
    "    self.layer4 = nn.MaxPool2d(kernel_size=2,stride=2) # (7*7*32)\n",
    "    # 여기서 부터는 max_pooling이 힘드니 바로 FC 써먹자|\n",
    "    self.layer5 = nn.Linear(7*7*32, num_classes) # 입력 차원, 출력 차원\n",
    "  \n",
    "  def forward(self, x):\n",
    "    # Debug 2. 여기서도 많이 씀\n",
    "    # pdb.set_trace()\n",
    "    out=self.layer1(x)\n",
    "    out=self.layer2(out)\n",
    "    out=self.layer3(out)\n",
    "    out=self.layer4(out)\n",
    "    out=out.reshape(out.size(0),-1) # 2차원을 1차원으로 펼치는 과정\n",
    "    out=self.layer5(out)\n",
    "    # print(out.shape)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (layer2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (layer4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (layer5): Linear(in_features=1568, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyper params\n",
    "num_epochs = 5\n",
    "num_classes = 10\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "device = torch.device('cpu')\n",
    "# 모델 초기화\n",
    "model = ConvNet()\n",
    "# 기존 weights 입력\n",
    "model.load_state_dict(torch.load('model_state_dict.pt',map_location=device))\n",
    "# 모델 실행\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28, 28, 1])\n"
     ]
    }
   ],
   "source": [
    "# 이미지 읽어오는지 확인\n",
    "filename = \"./image/mnistimg.png\"\n",
    "image = cv2.imread(filename)\n",
    "image = cv2.resize(image, (28, 28))\n",
    "image = image[:,:,:1]\n",
    "image = torch.from_numpy(image)\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# torchvision으로 읽기\n",
    "trans = transforms.Compose([\n",
    "    transforms.Resize((28,28)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "testset = torchvision.datasets.ImageFolder(root=\"C:\\kjy\\py_workspace\\Flask_Practice\", transform=trans)\n",
    "testloader = torch.utils.data.DataLoader(dataset=testset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "for image, label in testloader:\n",
    "    image=image.to(device)\n",
    "    outputs = model(image[:,:1])\n",
    "    _,predicted=torch.max(outputs.data, 1)\n",
    "    print(str(predicted.numpy()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
