{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IL6dIhEak3HO"
   },
   "source": [
    "# 머신러닝 Workshop2 - 측정 공식(Evaluation Metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금까지 선형 회귀(Linear Regression), 로지스틱 회귀(Logistic Regression) 등 많은 알고리즘을 다뤘지만 현업에서, 그리고 실제 연구에서 이 알고리즘을 사용하기 위해서는 알고리즘의 성능을 정량적으로 측정하고 그 성능을 분석하는게 중요합니다. 이번 시간에는 구현한 머신러닝 모델의 성능을 평가(evaluate)하는 다양한 방법에 대해 살펴볼 것입니다.\n",
    "\n",
    "측정 공식은 크게 1) 분류(Classification) 문제인지 2) 회귀(Regression) 문제인지에 따라 달라집니다. 먼저 분류 문제부터 보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cCGHzn7ak3IY"
   },
   "source": [
    "## 분류(Classification) 문제에서 사용하는 측정 공식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B2IwGwjJk3IZ"
   },
   "source": [
    "### 오차행렬(Confusion Matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rak6ez5fk3Ia"
   },
   "source": [
    "이진 분류 모델의 성능을 평가하는 방법으로 잘 활용되는 방법은 Confusion Matrix를 만들어보는 것입니다. Confusion Matrix는 다음과 같은 2x2 행렬에서 실제값과 예측값이 어떻게 매핑되는지를 나타냅니다. \n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1bcJ-dYqnocfV7EOs7nXAJ9cWq1Oq5BWd\" width=\"800\">\n",
    "\n",
    "\n",
    "이진 분류에서 사용하는 용어 중 \"**positive**\"와 \"**negative**\"는 모델이 내놓은 예측값 기준으로 분류한 것이고, \"**true**\"와 \"**false**\"는 예측값과 실제값의 일치 여부를 기준으로 분류한 것입니다. 각 경우별로 살펴본다면 다음과 같습니다. <br>\n",
    "- True Negative(TN): 실제 False인 값을 False라고 예측 (정답)\n",
    "- False Positive(FP): 실제 False인 값을 True라고 예측 (오답)\n",
    "- False Negative(FN): 실제 True인 값을 False라고 예측 (오답)\n",
    "- True Positive(TP): 실제 True인 값을 True라고 예측 (정답) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "evnfPQSdk3Ib"
   },
   "source": [
    "우선, 분류 모델에 대한 측정 공식을 알아보기 위한 예제 데이터셋을 랜덤으로 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8btgwg9sk3Ic",
    "outputId": "52c039b3-967c-4eb3-f2fb-f5a5f39c2aae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20,)\n",
      "(20,)\n",
      "[1 0 1 1 0 0 1 1 1 0 0 0 0 1 0 1 1 1 1 1]\n",
      "[0 0 0 1 1 1 1 0 0 0 1 1 0 0 0 1 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# numpy를 사용하여 랜덤한 값을 만들 것입니다. \n",
    "# numpy의 random(np.random)은 랜덤 값을 생성하는 기능들을 포함하고 있습니다. \n",
    "# 코드를 실행할 때마다 랜덤으로 값이 만들어지기 때문에 결과를 고정하기 위해 seed를 고정합니다.\n",
    "np.random.seed = 123\n",
    "\n",
    "# np.random.randint()는 최솟값(low), 최대값(high), 개수(size)를 입력받습니다. \n",
    "# 최솟값과 최댓값 사이에서 지정한 개수만큼 랜덤하게 정수(Integer)를 추출합니다.\n",
    "y_true = np.random.randint(low=0, high=2, size=20)\n",
    "y_pred = np.random.randint(low=0, high=2, size=20)\n",
    "\n",
    "# y_true와 y_pred의 shape를 확인합니다.\n",
    "# 20개가 잘 뽑혔다면 (20, 1) 또는 (20, )이 출력됩니다.\n",
    "print(y_true.shape)\n",
    "print(y_pred.shape)\n",
    "\n",
    "# y_true와 y_pred의 값을 확인합니다.\n",
    "print(y_true)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6iBbXVU3k3If"
   },
   "source": [
    "사이킷런은 Confusion Matrix를 만드는 **confusion_matrix()** API를 제공합니다. 실제값인 y_true와 예측값인 y_pred를 confusion_matrix()의 인자로 입력합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qDilyGynk3If",
    "outputId": "91064f93-0946-4ad5-df12-d193320971b6"
   },
   "outputs": [],
   "source": [
    "# 사이킷런의 confusion_matrix를 불러옵니다.\n",
    "# Evaluation Metric과 관련된 함수는 사이킷런의 metrics에 포함되어 있습니다.\n",
    "# Write your code!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xm7lf4Zwk3Ih"
   },
   "source": [
    "출력된 Confusion Matrix은 array 형태입니다. 이진 분류의 TN, FP, FN, TP는 위의 표에서와 위치가 같습니다. 즉, TN은 array[0,0], FP는 array[0,1], FN은 array[1,0], TP는 array[1,1]에 해당합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vmoBpv3Uk3Ii",
    "outputId": "fbe8b8e1-c7e3-4361-c7a0-c828214ad5e8"
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix의 각 요소를 가져와봅시다. \n",
    "# Write your code!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VDRtvw22k3Il"
   },
   "source": [
    "### 정확도(Accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "69RWG_2Ek3Il"
   },
   "source": [
    "Accuracy는 실제값과 예측값이 얼마나 같은지를 판단하는 지표입니다. 즉, Confusion Matrix에서 True에 해당하는 값인 **TN**과 **TP**에 좌우됩니다. Accuracy는 Confusion Matrix와 관련하여 다음과 같이 정의될 수 있습니다.\n",
    "$$ Accuracy = \\frac{예측값과 실제값이 일치하는 데이터 수}{전체 데이터 수} = \\frac{TN + TP}{TN + FP + FN + TP}$$ \n",
    "\n",
    "Accuracy를 구하는 기능은 다음과 같이 구현할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PfBYrNZWk3Im",
    "outputId": "8bbc86eb-088a-4d1b-e4cf-9f531198788d"
   },
   "outputs": [],
   "source": [
    "# Write your code!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mx4J8ohsk3Iq"
   },
   "source": [
    "사이킷런은 Accuracy를 측정하는 **accuracy_score()** 함수를 제공합니다. 첫 번째 파라미터로 실제값, 두 번째 파라미터로 예측값을 입력하면 됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zMz--Laqk3Ir",
    "outputId": "6c9221b5-85c1-493d-89a8-953748105ff1"
   },
   "outputs": [],
   "source": [
    "# Write your code!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2buV-dBfk3It"
   },
   "source": [
    "그러나, **불균형한 데이터 세트**에서는 Accuracy만으로는 모델 신뢰도가 떨어질 수 있습니다. 예를 들어, 전체 데이터가 100개라고 할 때 10개만 1, 나머지 90개는 0인 데이터 세트가 있다고 가정합시다. 이 데이터 세트에 모든 데이터를 0으로 예측하는 모델을 이용해 Accuracy를 측정하면 90%의 Accuracy를 나타냅니다. 적절하지 않은 모델을 사용하고도 높은 수치가 나타날 수 있다는 것이 Accuracy를 평가 지표로 사용할 때의 문제점입니다. <br>\n",
    "\n",
    "불균형한 데이터 세트에서 Accuracy의 이러한 **단점을 보완**할 수 있는 평가 지표로 정밀도(Precision)와 재현율(Recall)이 있습니다. Precision와 Recall은 \"**positive**\" 데이터 세트의 예측 성능에 좀더 초점을 맞춘 평가 지표입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cFiuz37xk3It"
   },
   "source": [
    "### 정밀도(Precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ts_E-EY0k3Iu"
   },
   "source": [
    "Precision는 \"positive\"로 예측한 대상 중에 예측값과 실제값이 일치하는 데이터의 비율을 말합니다. 따라서 Precision이 높을수록 좋은 모형입니다. Precision는 Confusion Matrix와 관련하여 다음과 같이 정의될 수 있습니다. \n",
    "$$Precision = \\frac{TP}{FP + TP} $$\n",
    "\n",
    "Precision을 구하는 기능은 다음과 같이 구현할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SKhibsP9k3Iw",
    "outputId": "ac6a0375-06c4-4f31-fc10-c118ec1ba21c"
   },
   "outputs": [],
   "source": [
    "# Write your code!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pulF5OKMk3Iy"
   },
   "source": [
    "사이킷런은 Precision을 계산하는 **precision_score()** 함수를 제공합니다. 첫 번째 파라미터로 실제값, 두 번째 파라미터로 예측값을 입력하면 됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sf27pc59k3Iz",
    "outputId": "9f04b980-348e-4948-c92b-8d15cdd61260"
   },
   "outputs": [],
   "source": [
    "# Write your code!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qhJ5ThJMk3I1"
   },
   "source": [
    "### 재현율(Recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m24LeOWbk3I2"
   },
   "source": [
    "Recall은 실제값이 \"positive\"인 대상 중에 예측값과 실제값이 일치하는 데이터의 비율을 말합니다. 따라서 Recall이 높을수록 좋은 모형입니다. Recall은 민감도(Sensitivity) 또는 TPR(True Positive Rate)라고도 불립니다. Recall은 Confusion Matrix와 관련하여 다음과 같이 정의될 수 있습니다.\n",
    "$$ Recall = \\frac{TP}{FN + TP} $$\n",
    "\n",
    "Recall을 구하는 기능은 다음과 같이 구현할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_L23CQYUk3I3",
    "outputId": "c591c941-c29b-423b-89bd-3b5697f4605a"
   },
   "outputs": [],
   "source": [
    "# Write your code!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YZ4kcreLk3I6"
   },
   "source": [
    "사이킷런은 재현율을 계산하는 **recall_score()** 함수를 제공합니다. 첫 번째 파라미터로 실제값, 두 번째 파라미터로 예측값을 입력하면 됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wt2x-CN0k3I7",
    "outputId": "e99f3862-db54-48d7-d61d-ba6b72a98621"
   },
   "outputs": [],
   "source": [
    "# Write your code!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oBGFi1C4k3I-"
   },
   "source": [
    "상황에 따라 Precision이 더 중요할 수도 있고 Recall이 더 중요한 지표가 될 수도 있습니다. <br>\n",
    "\n",
    "실제 \"negative\"인 데이터를 \"positive\"로 잘못 판단했을 때 업무상 큰 영향을 주는 경우에는 Precision이 상대적으로 더 중요한 지표가 됩니다. 반대로 실제 \"positive\"인 데이터를 \"negative\"로 잘못 판단했을 때 업무상 큰 영향을 주는 경우에는 Recall이 상대적으로 더 중요한 지표가 됩니다. <br>\n",
    "\n",
    "예를 들어 스팸 메일 여부를 판단하는 모델의 경우, 실제 스팸 메일(positive)인데 일반 메일(negative)로 분류한다면 사용자는 불편함을 느끼는 정도일 것입니다. 그러나 실제로 중요한 일반 메일(negative)를 스팸 메일(positive)로 분류하는 경우 업무에 차질이 생기게 될 것입니다. 이때에는 Precision이 더 중요한 지표가 됩니다. <br>\n",
    "\n",
    "다른 예로, 암 환자를 판단하는 모델에서는 Recall이 더 중요한 지표가 됩니다. 실제로 암 환자(positive)인데 암 환자가 아니라고(negative) 판단하는 경우에 제때 치료를 받지 못하게 되므로 심각한 문제를 일으킬 수 있습니다. 반면 실제로 암 환자가 아닌(negative) 경우에 암 환자(positive)인 것으로 잘못 판단되는 경우에는 재검사 비용이 소모되기는 하겠지만 생명을 앗아가지는 않을 것입니다. <br>\n",
    "\n",
    "Precision와 Recall의 공식을 살펴보면, 두 지표 모두 TP를 높이는 데 동일하게 초점을 맞추지만, Precision은 FP를, Recall은 FN을 낮추는 데 초점을 맞춥니다. 이러한 특성 때문에 Precision와 Recall은 분류의 성능을 평가하는 데 있어서 서로 보완적으로 작용합니다. <br>\n",
    "\n",
    "따라서 Precision와 Recall 중 어느 하나만 매우 높고 다른 수치는 매우 낮은 결과를 나타내는 경우 바람직하지 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T4vRX1lrk3JZ"
   },
   "source": [
    "## 2) 측정 공식 - 회귀 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "clqY3SkFk3Ja"
   },
   "source": [
    "이번에는 회귀 모델의 성능을 평가하는 방법에 대해 알아보겠습니다. <br>\n",
    "\n",
    "수치(Float) 값을 예측하는 모델은 정확도 등의 분류 모델 평가 기준으로 평가하는 것이 애매합니다. 분류 모델은 맞게 분류했는지/아닌지만 평가하면 되지만, 회귀 모델은 정확하게 예측하지 못했더라도, 정답과 비슷하게 맞추면 성능이 좋다고 평가해야 합니다. 따라서 회귀의 평가를 위한 지표는 실제값과 예측값의 차이를 기반으로 합니다. <br>\n",
    "\n",
    "이때 실제값과 예측값의 차이를 그냥 더하면 +와 -가 섞여서 오류가 상쇄됩니다. 이 때문에 오류의 절댓값 평균이나 제곱, 또는 제곱한 뒤 다시 루트를 씌운 평균값을 구합니다. 일반적으로 회귀의 성능을 평가하는 지표로는 **MAE**, **MSE**, **RMSE**, **R^2**, **MSLE**, **RMSLE** 등이 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qcYrsaYwk3Jb"
   },
   "source": [
    "우선, 회귀 모델에 대한 측정 공식을 알아보기 위한 예제 데이터셋을 랜덤으로 생성합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fgZ2MAcnk3Jb",
    "outputId": "6b013ade-d184-47c4-f803-1e022e0f77df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500,)\n",
      "(500,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>732</td>\n",
       "      <td>728.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>92</td>\n",
       "      <td>91.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>359</td>\n",
       "      <td>357.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>483</td>\n",
       "      <td>482.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>707</td>\n",
       "      <td>706.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>285</td>\n",
       "      <td>282.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>281</td>\n",
       "      <td>280.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>637</td>\n",
       "      <td>635.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>399</td>\n",
       "      <td>398.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>101</td>\n",
       "      <td>100.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    y_true  y_pred\n",
       "4      732   728.8\n",
       "5       92    91.8\n",
       "6      359   357.2\n",
       "7      483   482.2\n",
       "9      707   706.0\n",
       "10     285   282.5\n",
       "12     281   280.5\n",
       "13     637   635.8\n",
       "14     399   398.1\n",
       "15     101   100.7"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 코드를 실행할 때마다 랜덤으로 값이 만들어지기 때문에 결과를 고정하기 위해 seed를 고정합니다.\n",
    "np.random.seed = 123\n",
    "\n",
    "# np.random.randint()는 최솟값(low), 최대값(high), 개수(size)를 입력받습니다. \n",
    "# 최솟값과 최댓값 사이에서 지정한 개수만큼 랜덤하게 정수(Integer)를 추출합니다.\n",
    "y_true = np.random.randint(low=10, high=900, size=500)\n",
    "\n",
    "# np.random.random()는 개수(size)를 입력받습니다.\n",
    "# 구간 [0.0, 1.0)에서 지정한 개수만큼 랜덤하게 Floats를 추출합니다.\n",
    "y_pred = y_true + np.round(np.random.random(500), decimals=1) * np.random.randint(low=-10, high=10, size=500)\n",
    "\n",
    "# y_true와 y_pred의 shape를 확인합니다.\n",
    "# 500개가 잘 뽑혔다면 (500, 1) 또는 (500, )이 출력됩니다.\n",
    "print(y_true.shape)\n",
    "print(y_pred.shape)\n",
    "\n",
    "# y_true와 y_pred의 값을 확인합니다.\n",
    "y_df = pd.DataFrame(y_true, columns=['y_true'])\n",
    "y_df['y_pred'] = y_pred\n",
    "y_df[y_df['y_true'] > y_df['y_pred']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "497ipVCMk3Je"
   },
   "source": [
    "### MAE (Mean Absolute Error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PXCB5wylk3Je"
   },
   "source": [
    "MAE(Mean Absolute Error)는 실제값과 예측값의 차이를 **절댓값**으로 변환해 평균한 것입니다. \n",
    "$$ MAE = \\frac{1}{n}\\sum_{i=1}^{n}\\left|Y_{i}-\\hat{Y}_{i}\\right| $$\n",
    "\n",
    "MAE를 구하는 기능은 다음과 같이 구현할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bTn4Ll-Ik3Jf",
    "outputId": "920b88ad-844d-4b77-ab19-58535cc25a92"
   },
   "outputs": [],
   "source": [
    "# Write your code!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UpLPNa0ik3Jh"
   },
   "source": [
    "사이킷런은 MAE를 계산하는 **mean_absolute_error()** 함수를 제공합니다. 첫 번째 파라미터로 실제값을, 두 번째 파라미터로 예측값을 입력하면 됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nHCS-1xEk3Ji",
    "outputId": "02ba2da1-0eaf-4a81-aeb0-8f6a2a2a2083"
   },
   "outputs": [],
   "source": [
    "# Write your code!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Thmo3TG-k3Jk"
   },
   "source": [
    "### MSE (Mean Squared Error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IBK5_U57k3Jl"
   },
   "source": [
    "MSE(Mean Squared Error)는 실제값과 예측값의 차이를 **제곱**해 평균한 것입니다. \n",
    "$$ MSE = \\frac{1}{n}\\sum_{i=1}^{n}(Y_{i}-\\hat{Y}_{i})^2 $$\n",
    "\n",
    "MSE를 구하는 기능은 다음과 같이 구현할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e3wHCyclk3Jm",
    "outputId": "62654f4a-b68b-45d0-fedb-b2c6d25a3ac2"
   },
   "outputs": [],
   "source": [
    "# Write your code!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3sbakoVfk3Jo"
   },
   "source": [
    "사이킷런은 MSE를 계산하는 **mean_squared_error()** 함수를 제공합니다. 첫 번째 파라미터로 실제값을, 두 번째 파라미터로 예측값을 입력하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wdNx7SFvk3Jp",
    "outputId": "b52879a8-95e2-4554-d6cf-93c81312908b"
   },
   "outputs": [],
   "source": [
    "# Write your code!\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "07_Model_Evaluation-v2(수정중).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
